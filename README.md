# TFG - Análisis de Redes Convolucionales y Técnicas de Explicabilidad para Arquitecturas Neuronales Profundas para la Segmentación de Instancias

## Resumen

**PALABRAS CLAVE**: Redes Neuronales Convolucionales, Modelización Matemática, Ondículas, Visión por Computador, Aprendizaje Profundo, Segmentación de Instancias, Inteligencia Artificial Explicable.

Este Trabajo de Fin de Grado combina dos enfoques complementarios: por un lado, el desarrollo de una modelización matemática general de las redes neuronales convolucionales (CNN), y por otro, la implementación y evaluación de un modelo de segmentación de instancias en imágenes dentales con técnicas de inteligencia artificial explicable.

En la parte teórica, se extiende el análisis de Mallat sobre redes de dispersión mediante el marco propuesto por Wiatowski y Bölcskei, que permite caracterizar CNN profundas mediante marcos semi-discretos generales, funciones de activación y operadores de pooling Lipschitz-continuos. Bajo esta formulación, se demuestra la invarianza vertical a traslaciones, es decir, la creciente robustez del extractor de características ante desplazamientos espaciales conforme se profundiza en la red.

En la parte experimental, se aplica la arquitectura Mask R-CNN a la segmentación de instancias dentales en radiografías panorámicas. Se adapta el modelo preentrenado al dominio específico mediante ajuste fino y se le incorpora Grad-CAM siguiendo las adaptaciones propuestas por Inbaraj et al., con el objetivo de mejorar su interpretabilidad. La evaluación incluye métricas de detección, segmentación (DSC, IoU, HD) y explicabilidad (Deletion, Insertion, Stability, `IoU$_{\text{Grad-CAM}}$`), desglosadas por categoría dental.

El modelo ajustado alcanza un F1-Score del 96.04 %, una precisión del 97.36 %, un DSC del 87.76 % y un IoU del 79.23 % en el conjunto de test, superando ampliamente tanto al modelo base como a métodos clásicos de segmentación no supervisados. Además, en la comparativa con trabajos recientes de aprendizaje profundo, la propuesta iguala o supera arquitecturas como PANet o ResNeSt, destacando especialmente en interpretabilidad sin necesidad de cambiar el backbone.

Los resultados obtenidos refuerzan el valor de las CNN ajustadas al dominio y complementadas con técnicas de explicabilidad post-hoc como Grad-CAM, tanto para alcanzar precisión de estado del arte como para dotar de transparencia a modelos aplicables en contextos clínicos.

## Abstract

**KEYWORDS**: Mathematical Modeling, Translation Invariance, Deformation Invariance, Scattering Networks, Frame Theory, Wavelet Transform, Wavelets, Machine Learning, Computer Vision, Deep Learning, Convolutional Neural Networks, Feature Extraction, Instance Segmentation, Mask R-CNN, Explainable AI, Grad-CAM.

On one hand, the main mathematical purpose of the work detailed below is to develop a comprehensive mathematical modeling of convolutional neural networks, adapting to many of the most commonly used architectures for this type of network. Additionally, using this general modeling, one of the main properties of convolutional neural networks focused on feature extraction, namely translation invariance, will be demonstrated.

Convolutional neural networks have led to groundbreaking results in numerous practical machine learning tasks. Many of these applications first perform feature extraction and then feed the results into a trainable classifier. Their good performance in such tasks can be empirically verified. However, their mathematical modeling and theoretical justification for their effectiveness in these tasks remain an open area of research.

The mathematical analysis of convolutional neural networks for feature extraction was initiated by Mallat in his work *Group Invariant Scattering* in 2012. Specifically, Mallat considered the so-called scattering networks based on a wavelet transform followed by the modulus as a non-linear activation function in each layer of the network, and demonstrated translation invariance (asymptotically in the wavelet scale parameter) and invariance against small deformations of the corresponding feature extractor.

The mathematical part of this work builds on the article *A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction* by Thomas Wiatowski and Helmut Bölcskei, presented in 2017. This work generalizes Mallat’s results by developing a theory that encompasses general convolutional transformations, or in more technical terms, general semi-discrete frames (including wavelets, curvelets, ridgelets, learned filters, etc.), general Lipschitz-continuous non-linear activation functions (e.g., rectified linear units, shifted logistic sigmoids, hyperbolic tangents, and modulus functions), and general Lipschitz-continuous pooling operators that emulate, for example, subsampling and averaging. Moreover, all these elements can differ across the network’s layers. For the mathematical modeling of the resulting feature extractor, a vertical translation invariance result is demonstrated, meaning that the features become progressively more invariant to translation as the network depth increases.

On the other hand, the computational part of this work focuses on instance segmentation, a key process for detecting objects in a scene and generating masks that precisely extract these objects. This process involves two stages: first, detecting the rectangular region containing the object, and then generating a mask that segments the detected object, accurately defining its contours. In this context, the Mask R-CNN architecture has proven to be particularly effective for this task, providing promising results in instance segmentation. However, like many deep neural networks, Mask R-CNN faces challenges in terms of interpretability, meaning the difficulty in understanding the reasoning behind its decisions.

To improve the interpretability of Mask R-CNN, this work proposes the application of Grad- CAM, a post-hoc interpretability method that allows for visualizing the regions of an image that most influence the network’s decisions. The implementation of Grad-CAM on Mask R-CNN, based on adaptations proposed in previous research, aims to enhance the understanding of the inference processes of this neural architecture. Thus, this work intends to provide explainability to a model that would otherwise be a black box.
