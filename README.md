# TFG - Análisis de Redes Convolucionales y Técnicas de Explicabilidad para Arquitecturas Neuronales Profundas de Segmentación de Instancias

## Resumen

**PALABRAS CLAVE:** Modelización Matemática, Invarianza a Traslaciones, Invarianza frente a Deformaciones, Redes de Dispersión, Teoría de Marcos, Transformada de Ondículas, Ondículas, Aprendizaje Automático, Visión por Computador, Aprendizaje Profundo, Redes Neuronales Convolucionales, Extracción de Características, Segmentación de Instancias, Mask R-CNN, IA Explicable, Grad-CAM.

Por un lado, el propósito matemático principal del trabajo detallado a continuación es desarrollar una modelización matemática general de las redes neuronales convolucionales, de manera que se adapte muchas de las arquitecturas más comúnmente utilizadas para este tipo de redes. Además, utilizando esta modelización general, se demostrará una de las propiedades principales de las redes neuronales convolucionales enfocadas en la extracción de características, la invarianza vertical a traslaciones.

Las redes neuronales convolucionales han llevado a resultados innovadores en numerosas tareas prácticas de Aprendizaje Automático. Muchas de estas aplicaciones realizan primero la extracción de características y luego introducen los resultados en un clasificador entrenable. Su buen rendimiento en este tipo de tareas puede comprobarse empíricamente. Sin embargo, su modelización matemática y la justificación teórica de por qué son buenos para estas tareas sigue siendo un estudio de caso abierto.

El análisis matemático de las redes neuronales convolucionales para la extracción de características fue iniciado por Mallat en su trabajo *Group Invariant Scattering* en 2012. Específicamente, Mallat consideró las llamadas redes de dispersión basadas en una transformada de ondículas seguida del módulo como función de activación no-lineal en cada capa de la red, y demostró la invarianza a traslaciones (asintóticamente en el parámetro de escala de ondículas) y la invarianza frente a pequeñas deformaciones del extractor de características correspondiente.

La parte matemática de este trabajo se basa en el artículo *A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction* presentado por Thomas Wiatowski y Helmut Bölcskei en 2017. Este generaliza los resultados de Mallat desarrollando una teoría que abarca transformaciones convolucionales generales, o en términos más técnicos, marcos semi-discretos generales (incluyendo ondículas, curvículas, crestículas, filtros aprendidos, etc.), funciones de activación no-lineales Lipschitz-continuas generales (por ejemplo, unidades lineales rectificadas, sigmoides logísticos desplazados, tangentes hiperbólicas y funciones de módulo) y operadores de pooling Lipschitz-continuos generales que emulan, por ejemplo, el submuestreo y el pooling promedio. Además, todos estos elementos pueden ser diferentes en las distintas capas de la red. Para la modelización matemática del extractor de características resultante, se demuestra un resultado de invarianza a la traslación de naturaleza vertical en el sentido de que las características se vuelven progresivamente más invariantes a la traslación con el aumento de la profundidad de la red.

Por otro lado, la parte informática de este trabajo se centra en la segmentación de instancias, un proceso clave para detectar objetos en una escena y generar máscaras que permitan extraer con precisión dichos objetos. Este proceso implica dos etapas: primero, la detección de la región rectangular que contiene el objeto y, posteriormente, la generación de una máscara que segmenta el objeto detectado, definiendo con precisión sus contornos. En este contexto, la arquitectura Mask R-CNN ha demostrado ser particularmente efectiva para esta tarea, proporcionando resultados prometedores en la segmentación de instancias. Sin embargo, como muchas redes neuronales profundas, Mask R-CNN presenta limitaciones en términos de interpretabilidad, es decir, la dificultad para comprender las razones detrás de sus decisiones.

Con el objetivo de mejorar la interpretabilidad de Mask R-CNN, este trabajo propone la aplicación de Grad-CAM, un método de interpretabilidad post-hoc que permite visualizar las regiones de una imagen que influyen más en las decisiones de la red. La implementación de Grad-CAM sobre Mask R-CNN, basada en adaptaciones propuestas en investigaciones previas, busca facilitar la comprensión de los procesos de inferencia de esta arquitectura neuronal. De este modo, en este trabajo se pretende dotar de explicabilidad a un modelo que de otro modo sería una caja negra.

## Abstract

**KEYWORDS:** Mathematical Modeling, Translation Invariance, Deformation Invariance, Scattering Networks, Frame Theory, Wavelet Transform, Wavelets, Machine Learning, Computer Vision, Deep Learning, Convolutional Neural Networks, Feature Extraction, Instance Segmentation, Mask R-CNN, Explainable AI, Grad-CAM.

On one hand, the main mathematical purpose of the work detailed below is to develop a comprehensive mathematical modeling of convolutional neural networks, adapting to many of the most commonly used architectures for this type of network. Additionally, using this general modeling, one of the main properties of convolutional neural networks focused on feature extraction, namely translation invariance, will be demonstrated.

Convolutional neural networks have led to groundbreaking results in numerous practical machine learning tasks. Many of these applications first perform feature extraction and then feed the results into a trainable classifier. Their good performance in such tasks can be empirically verified. However, their mathematical modeling and theoretical justification for their effectiveness in these tasks remain an open area of research.

The mathematical analysis of convolutional neural networks for feature extraction was initiated by Mallat in his work *Group Invariant Scattering* in 2012. Specifically, Mallat considered the so-called scattering networks based on a wavelet transform followed by the modulus as a non-linear activation function in each layer of the network, and demonstrated translation invariance (asymptotically in the wavelet scale parameter) and invariance against small deformations of the corresponding feature extractor.

The mathematical part of this work builds on the article *A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction* by Thomas Wiatowski and Helmut Bölcskei, presented in 2017. This work generalizes Mallat’s results by developing a theory that encompasses general convolutional transformations, or in more technical terms, general semi-discrete frames (including wavelets, curvelets, ridgelets, learned filters, etc.), general Lipschitz-continuous non-linear activation functions (e.g., rectified linear units, shifted logistic sigmoids, hyperbolic tangents, and modulus functions), and general Lipschitz-continuous pooling operators that emulate, for example, subsampling and averaging. More- over, all these elements can differ across the network’s layers. For the mathematical modeling of the resulting feature extractor, a vertical translation invariance result is demonstrated, meaning that the features become progressively more invariant to translation as the network depth increases.

On the other hand, the computational part of this work focuses on instance segmentation, a key process for detecting objects in a scene and generating masks that precisely extract these objects. This process involves two stages: first, detecting the rectangular region containing the object, and then generating a mask that segments the detected object, accurately defining its contours. In this context, the Mask R-CNN architecture has proven to be particularly effective for this task, providing promising results in instance segmentation. However, like many deep neural networks, Mask R-CNN faces challenges in terms of interpretability, meaning the difficulty in understanding the reasoning behind its decisions.

To improve the interpretability of Mask R-CNN, this work proposes the application of Grad-CAM, a post-hoc interpretability method that allows for visualizing the regions of an image that most influence the network’s decisions. The implementation of Grad-CAM on Mask R-CNN, based on adaptations proposed in previous research, aims to enhance the understanding of the inference processes of this neural architecture. Thus, this work intends to provide explainability to a model that would otherwise be a black box.
